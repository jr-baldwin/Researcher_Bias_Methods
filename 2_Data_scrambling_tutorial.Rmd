---
title: "Data Scrambling Tutorial"
author: "Jessie Baldwin"
output: 
  github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

**This tutorial demonstrates how to use 'data scrambling' to blind your data, to allow proposed analyses to be trialled without insight into the findings. This involves randomly shuffling the data points so that any associations between variables are obscured, whilst the variable distributions (and amounts of missing data) remain the same. All analyses will be conducted within R.**

**Please note that data scrambling was originally proposed by Profs Robert J. MacCoun and Saul Perlmutter; for more information, please see [here](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119095910.ch15?saml_referrer) for a detailed description and simulated examples.**

<br>

### Overview of tutorial

#### [1: Simulate data](#link1)
#### [2: Scramble data](#link2)
#### [3: Compare scrambled and non-scrambled data](#link3)

<br>

# 1: Simulate data<a name="link1"></a>

For the sake of this tutorialgit config --global user.name "YOUR_USERNAME", we will first simulate data to be scrambled. If you wish to scramble your own dataset without following the simulation, please skip to [Scramble data](#link2) for the code.

The simulated dataset will comprise 1000 observations across 5 variables, 2 of which are the predictor and outcome variable for the regression of interest. This simulation was adapted from Prof. Dorothy Bishop's scripts which can be found at: https://osf.io/gupxv/ 

<br>

#### Install and load packages

Please first install and load the following packages. 

```{r, message=FALSE, eval=FALSE}
install.packages("MASS")
install.packages("tidyr")
install.packages("dplyr")
install.packages("psych")
```

If you have already installed them, you can skip to loading them using the code below.

```{r, message=FALSE}
library(MASS)
library(tidyr)
library(dplyr)
library(psych)
```

<br>

#### Specify parameters for the simulated variables<a name="link4"></a>

Below we specify parameters for the simulation, including:
- number of variables
- sample size
- mean value for the variables
- variance of the variables
- correlations between predictor variables
- correlations between each predictor with the outcome 

```{r}
nVar <- 4 # Number of simulated variables (we will treat the 4th variable as the outcome)
N <- 1000 # Sample size for simulated dataset 
mean <- 0 # Mean score for all variables in the sample - we're using z scores for simplicity
var <- 1 # Variance of all variables. For z-scores, SD is 1, so variance is also 1
cor <- 0.3 # Correlation between predictor variables (this is arbitrary)
corDV <- c(0, 0, 0.2, 1) # Correlation between each predictor and the outcome. The final '1' is the variance of the outcome, in effect, the correlation of each variable with itself.
```

<br>

#### Generate a correlation matrix for the simulated variables

We will next generate a correlation matrix for the correlations between all the variables to be simulated.

```{r}
covMatrix <- matrix(rep(cor, nVar*nVar), nrow=nVar) # create a matrix with correlation value 
# Now we change the final row and column to show the correlation with the outcome. 
covMatrix[nVar, ] <- corDV # note that we specify nVar to indicate last row, but leave blank after the comma: this means we want all columns
covMatrix[, nVar] <- corDV #note that we leave blank before comma to indicate we want all rows; nVar indicates we want last column
diag(covMatrix) <- var # Change diagonal corresponding to the variance of all variables
covMatrix
```

<br>

#### Generate simulated data from specified means, variances, and covariance matrix 

We will now simulate the dataset from the specified parameters.

```{r}
set.seed(109) # Set seed for reproducibility
sim_data <- data.frame(id=1:N, mvrnorm(n = N, rep(mean, nVar), covMatrix)) # Include ID variable
head(sim_data)
dim(sim_data)
```

We can see that the simulated data includes an ID variable and 4 other variables, with 1000 rows.

<br>

#### Generate some missing data in the simulated dataset

We will now convert some of the simulated data to missing. This in order to test whether data scrambling affects the amount of missing data in a variable.

```{r}
# Specify variables X3 and X4 to have missing data 
c_names <- c("X3","X4")

# Specify 20% missing data 
prc_missing <- 0.20
n_remove <- prc_missing * nrow(sim_data)

# Input missing data into simulated dataset
sim_data <- sim_data %>%
  gather(var, value, -id) %>%   # reshape data
  sample_frac(1) %>%            # shuffle rows
  group_by(var) %>%             # for each variables
  mutate(value = ifelse(var %in% c_names & row_number() <= n_remove, NA, value)) %>%  # update to NA top x number of rows if it's one of the variables you specified
  spread(var, value)   %>%         # reshape to original format
  as.data.frame()
```

<br>

#### Describe simulated dataset

Let's have a look at the simulated dataset and run some descriptives.
```{r}
head(sim_data)
tail(sim_data)
dim(sim_data)
describe(sim_data)
```

This shows that:

- There are 1000 rows and 5 variables in the dataset
- Variables X3 and X4 have 20% missing data (N=800 instead of N=1000 in the other variables). 
- The means of X1-X4 are close to 0 and the standard deviations are close to 1 as we [specified above](#link4). 

<br>

#### Run regression testing the association between two variables of interest.

We will now test the association between X3 and X4, the variables we simulated to have a correlation of r=0.2.
```{r}
reg_unscrambled <- lm(X4 ~ X3, data=sim_data)
summary(reg_unscrambled)
```

We can see a statistically significant association between X3 and X4 (beta=0.26, SE=0.04, p=0.00).

<br>

# 2: Scramble data<a name="link2"></a>

Scrambling data (also known as data shuffling) is surprisingly easy. It can be achieved using the 'sample' function.

Below we scramble data for each row individually (meaning that all relationships between variables will be obscured). We do so following the advice in [this Stack Overflow post]( https://stackoverflow.com/questions/32620534/reshuffle-the-sequence-of-rows-in-data-frame).
```{r}
scrambled_data <- as.data.frame(lapply(sim_data, function(x) { sample(x)}))
```

<br>

# 3: Compare scrambled and non-scrambled data<a name="link3"></a>

Let's have a look at the data before and after scrambling, ordering by ID. In practice, the person who scrambled the data (not the lead researcher) should do this as a check that the scrambling has worked.

<br>

#### Check data structure of the original dataset
```{r}
head(sim_data[sim_data$id<10,], 10) 
```

#### Check data structure of the scrambled dataset
```{r}
head(scrambled_data[order(scrambled_data$id),], 10)
```

We can see that the values differ in the scrambled dataset, including the cells with missing data.

<br>

#### Check descriptives in the original dataset
```{r}
describe(sim_data) 
```

#### Check descriptives in the scrambled dataset
```{r}
describe(scrambled_data) # Scrambled dataset
```

We can see that the descriptives for all variables are exactly the same before and after scrambling. This means that the scrambled dataset is informative about the distributions and amounts of missingness in the data.

<br>

#### Run regression of interest in the scrambled dataset

We will now test the association between X4 and X3 in the scrambled dataset
```{r}
reg_scrambled <- lm(X4 ~ X3, data=scrambled_data)
summary(reg_scrambled)
```

In the scrambled dataset, there is no association between X4 and X3 (beta= -0.029, SE=0.039, p=0.45). Let's compare this to the true association in the unscrambled dataset.

#### Run regression of interest in the original dataset

```{r}
summary(reg_unscrambled)
```

The true statistically significant association (beta=0.26, SE=0.04) is present in the original dataset, but not in the scrambled dataset. 

This means that the scrambling procedure has obscured the significant association between variables, whilst retaining the distribution of the variables and amounts of missingness.
